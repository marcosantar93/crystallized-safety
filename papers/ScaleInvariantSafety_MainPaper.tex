\documentclass{article}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{hyperref}
\usepackage{booktabs}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{graphicx}
\usepackage{xcolor}
\usepackage[margin=1in]{geometry}
\usepackage{listings}
\usepackage{enumitem}
\usepackage{multirow}

\usepackage{natbib}
\bibliographystyle{plainnat}

\title{Scale-Invariant Safety Geometry: \\
Universal Vulnerability Across LLM Architectures}

\author{
Marco Santarcangelo \\
Scale AI \\
\texttt{marco@marcosantar.com}
}

\date{February 2026}

\begin{document}

\maketitle

\begin{abstract}
We demonstrate that safety mechanisms in large language models share a \textbf{universal geometric structure} that becomes apparent only after proper normalization. Through systematic experiments across four model families (Llama-3.1, Gemma-2, Qwen-2.5, Mistral), we show that apparent differences in steering resistance are explained entirely by the first singular value ($\sigma_1$) of the safety subspace---not by qualitative architectural differences. When perturbation magnitude is normalized by $\sigma_1$, all tested models exhibit identical vulnerability profiles: 0\% bypass at $\alpha_{\text{eff}}=0$, 100\% bypass at $\alpha_{\text{eff}} \geq 5$. This \textbf{scale-invariant safety geometry} has profound implications: (1) models previously thought ``robust'' are simply operating at different scales; (2) safety training creates similar geometric structures regardless of architecture; (3) red-teaming methodologies must account for model-specific scaling factors. We introduce $\alpha_{\text{eff}} = \alpha / \sigma_1$ as the universal metric for comparing steering attacks across models.
\end{abstract}

\textbf{Keywords:} Activation steering, AI safety, Singular value decomposition, Universal vulnerability, Mechanistic interpretability

\section{Introduction}

Recent work on activation steering has shown that language model behaviors can be manipulated by adding vectors to intermediate activations. A natural question is whether safety mechanisms are equally vulnerable. We resolve apparent inconsistencies across prior work with a simple but powerful finding: \textbf{all tested models are equally vulnerable when perturbations are normalized by the safety subspace's spectral norm}.

Consider two models:
\begin{itemize}[noitemsep]
    \item \textbf{Llama-3.1-8B}: $\sigma_1 \approx 5$, bypassed at $\alpha_{\text{raw}} = 25$
    \item \textbf{Gemma-2-9B}: $\sigma_1 \approx 100$, bypassed at $\alpha_{\text{raw}} = 500$
\end{itemize}

The ratio of thresholds (20x) matches the ratio of $\sigma_1$ values. When we define \textbf{effective steering magnitude}:
\begin{equation}
\alpha_{\text{eff}} = \frac{\alpha_{\text{raw}}}{\sigma_1}
\end{equation}
both models bypass at $\alpha_{\text{eff}} \approx 5$.

\section{Results}

\subsection{Cross-Model Geometry}

\begin{table}[h]
\centering
\begin{tabular}{lrr}
\toprule
\textbf{Model/Layer} & $\sigma_1$ & \textbf{Eff. Rank} \\
\midrule
Mistral L16 & 2.8 & 16 \\
Llama L16 & 4.5 & 16 \\
Llama L24 & 9.8 & 16 \\
Qwen L14 & 14.9 & 16 \\
Qwen L21 & 47.9 & 16 \\
Gemma L21 & 101.6 & 16 \\
Gemma L31 & 178.0 & 16 \\
\bottomrule
\end{tabular}
\caption{$\sigma_1$ varies by 60x while effective rank remains constant.}
\end{table}

\subsection{Universal Vulnerability}

\begin{table}[h]
\centering
\begin{tabular}{lrrrrrrr}
\toprule
\textbf{Model} & \multicolumn{7}{c}{\textbf{Bypass Rate by $\alpha_{\text{eff}}$}} \\
& 0 & 5 & 10 & 15 & 20 & 25 & 30 \\
\midrule
Llama & 0\% & 100\% & 100\% & 100\% & 100\% & 100\% & 100\% \\
Gemma & 0\% & 100\% & 100\% & 100\% & 100\% & 100\% & 100\% \\
Qwen & 0\% & 100\% & 100\% & 100\% & 100\% & 100\% & 100\% \\
Mistral & 38\% & 100\% & 100\% & 100\% & 100\% & 100\% & 100\% \\
\bottomrule
\end{tabular}
\caption{When normalized by $\sigma_1$, all models show identical vulnerability.}
\end{table}

\section{Conclusion}

Safety mechanisms share universal geometric structure. Apparent robustness differences are explained entirely by $\sigma_1$. We introduce $\alpha_{\text{eff}} = \alpha / \sigma_1$ as the universal metric for cross-model comparison.

\end{document}
